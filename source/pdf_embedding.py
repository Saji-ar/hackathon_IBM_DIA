# --- D√©pendances √† installer si besoin ---
# pip install pypdf lancedb sentence-transformers pandas

import re
from pathlib import Path

import pandas as pd
from pypdf import PdfReader
import lancedb
from sentence_transformers import SentenceTransformer

# -------- 1) Chargement du PDF --------
pdf_path = "/content/reglint.pdf"  # <-- adapte si besoin
reader = PdfReader(pdf_path)

def clean_text(t: str) -> str:
    # Nettoyage l√©ger : espaces, sauts de lignes multiples, hyphens de c√©sure, etc.
    t = re.sub(r"-\n", "", t)                 # casse mots coup√©s par c√©sure
    t = re.sub(r"\s+\n", "\n", t)
    t = re.sub(r"\n{2,}", "\n\n", t)
    t = re.sub(r"[ \t]{2,}", " ", t)
    return t.strip()

# -------- 2) Extraction page par page + rep√©rage de sections --------
pages = []
for i, page in enumerate(reader.pages, start=1):
    raw = page.extract_text() or ""
    pages.append({"page": i, "text": clean_text(raw)})

# Heuristique simple pour d√©tecter des en-t√™tes/sections (Pr√©ambule, Article X, etc.)
SECTION_PAT = re.compile(r"^(Pr√©ambule|Article\s+\d+[^:\n]*|ANNEXE\s*\d+)", re.IGNORECASE)

def annotate_sections(pages):
    current_section = "Document"
    annotated = []
    for p in pages:
        # Cherche un titre de section au d√©but de la page
        first_lines = p["text"].splitlines()[:12]
        section_found = None
        for line in first_lines:
            m = SECTION_PAT.match(line.strip())
            if m:
                section_found = m.group(0).strip()
                break
        if section_found:
            current_section = section_found
        annotated.append({**p, "section": current_section})
    return annotated

pages = annotate_sections(pages)

# -------- 3) Chunking du texte pour RAG --------
# Chunk ~800‚Äì1000 caract√®res avec overlap 150 pour du FR/longs articles
CHUNK_SIZE = 500
OVERLAP = 150

def chunk_text(text, page, section, size=CHUNK_SIZE, overlap=OVERLAP):
    text = text.strip()
    if not text:
        return []
    chunks = []
    start = 0
    n = len(text)
    while start < n:
        end = min(start + size, n)
        # Essaie de couper sur un s√©parateur "propre" si possible
        slice_ = text[start:end]
        if end < n:
            # recule jusqu'au dernier point/fin de ligne pour √©viter de couper une phrase
            cut = max(slice_.rfind("\n"), slice_.rfind(". "))
            if cut != -1 and cut > size * 0.5:
                end = start + cut + 1
                slice_ = text[start:end]
        chunks.append({
            "page": page,
            "section": section,
            "chunk": slice_.strip()
        })
        start = max(end - overlap, end)  # g√®re le cas overlap > restant
    return chunks

records = []
for p in pages:
    records.extend(chunk_text(p["text"], p["page"], p["section"]))

df = pd.DataFrame.from_records(records)
print(f"üìÑ Pages: {len(pages)} | üß© Chunks: {len(df)}")
print(df.head(2))

# -------- 4) Mod√®le d‚Äôembedding --------
# Multilingue, bon pour du FR
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

# Embeddings
df["embedding"] = df["chunk"].apply(lambda x: model.encode(x).tolist())

# (facultatif) Quelques m√©tadonn√©es utiles pour filtrer
df["source_file"] = Path(pdf_path).name

# -------- 5) LanceDB : cr√©ation/√©criture --------
db = lancedb.connect("lancedb_reglement")     # dossier local
table = db.create_table(
    "reglement_chunks",
    data=df.to_dict(orient="records"),
    mode="overwrite"  # remet √† z√©ro si existe
)

print(f"‚úÖ Base cr√©√©e : {len(df)} chunks ins√©r√©s")
print("Champs : chunk, page, section, source_file, embedding")

# -------- 6) Exemple de recherche --------
# Pose ta requ√™te en langage naturel (FR ok).
query = "Quelles sont les r√®gles sur l'utilisation des t√©l√©phones pendant les examens ?"
query_vec = model.encode(query)

results = (
    table.search(query_vec, vector_column_name="embedding")
         .limit(5)
         .to_pandas()
)

# Affichage condens√©
cols_to_show = ["section", "page", "chunk"]
print("\nüîç R√©sultats similaires :")
for _, row in results[cols_to_show].iterrows():
    print(f"\n‚Äî {row['section']} (p.{int(row['page'])})")
    print(row["chunk"][:600] + ("‚Ä¶" if len(row["chunk"]) > 600 else ""))